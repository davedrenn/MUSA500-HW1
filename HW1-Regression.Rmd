---
title: "HW1-OLS_Regression"
output: html_document
date: "2023-10-19"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(here)
library(tidyverse)
library(kableExtra)
library(sf)
library(gridExtra)
library(MASS)
library(DAAG)
library(corrr)      # another way to plot correlation plot

options(scipen = 999)
```

# Introduction

# Methods
## Data Cleaning

The data set used in our analysis contains information from the 2000 US Census for Philadelphia, with neighborhood characteristic variables included for 1,720 block groups. Our analysis incorporates the following variables:

- POLY_ID: Census Block Group ID
- MEDHVAL: Median value of all owner occupied housing units
- PCBACHMORE: Proportion of residents in Block Group with at least a bachelor‚Äôs degree
- PCTVACANT: Proportion of housing units that are vacant
- PCTSINGLES: Percent of housing units that are detached single family houses 
- NBELPOV100: Number of households with incomes below 100% poverty level (i.e., number of households living in poverty)
- MEDHHINC: Median household income

The original data set had 1,816 block groups and was cleaned using the following methods, which reduced to the total number of observations to 1,720:

- Block groups where population < 40
- Block groups where there are no housing units
- Block groups where the median house value is lower than $10,000
- One North Philadelphia block group which had a very high median house value (over \$800,000) and a very low median household income (less than \$8,000)

In this analysis, we will examine the relationships between our dependent variable, MEDHVAL, and the predictors PCBACHMORE, NBELPOV100, PCTVACANT, and PCTSINGLES.

## Exploratory Data Analysis

We will examine the summary statistics and distributions of the data set‚Äôs variables, including the mean and standard deviation of our dependent variable and predictor variables.

As part of our exploratory data analysis, we will examine the Pearson correlations between the predictors. A Pearson correlation is a standardized measurement of the strength and direction of the linear relationship between two variables. The correlation between two variables is calculated using the following equation:

equation

The Pearson correlation value ranges between -1 to 1, with no units of measurement attached, and the observed variables are interchangeable between the x and y axis. A value of -1 represents a perfect negative linear relationship and a value of 1 represents a perfect positive linear relationship - in either case, points on a graph would appear in a straight line with either a negative or positive slope, respectively. 

A Pearson correlation value of 0 indicates that there is no linear relationship between two variables. However, a different type of relationship can exist, such as an exponential or quadratic relationship, that the Pearson correlation does not measure. 

## Multiple Regression Analysis

## Additional Analyses

## Software

This report used the open source software R to conduct statistical analyses.

# Results

## Exploratory Results

```{r data}

data <- read.csv("Data/RegressionData.csv")

```

### Summary Statistics

This table below shows the mean and standard deviation for our independent variable (Median house value) and our four dependent variables. 
The average median home value for census block groups in Philadelphia is 66,287.73 USD, and the standard deviation is 60,006 USD. The large standard deviation indicates a large amount of variability in average home sale prices across the different census block groups in Philadelphia. 

```{r table}

summary_stats_mean <- data %>%
  summarise(HEDVAL = mean(MEDHVAL),
            PCTBACHMOR = mean(PCTBACHMOR),
            NBELPOV100 = mean(NBELPOV100),
            PCTVACANT = mean(PCTVACANT),
            PCTSINGLE = mean(PCTSINGLES)) %>%
  gather(key = "variable", value = "mean")
            
summary_stats_sd <- data %>%
  summarise(HEDVAL = sd(MEDHVAL),
            PCTBACHMOR = sd(PCTBACHMOR),
            NBELPOV100 = sd(NBELPOV100),
            PCTVACANT = sd(PCTVACANT),
            PCTSINGLE = sd(PCTSINGLES)) %>%
  gather(key = "variable", value = "sd") %>%
  mutate(row_names = c('Median Houme Value of all occupied housing units','% of Individuals with Bachelor Degrees or Higher','# Households Living in Poverty','% of Vacant Houses','% of Single House Units')) 

left_join(summary_stats_mean, summary_stats_sd, by='variable') %>%
  dplyr::select('row_names','mean','sd') %>%
  kbl(col.names = c('Variable','Mean','Standard Deviation')) %>%
  kable_classic()
  
```


```{r 0_value_check2, eval=FALSE, echo=FALSE}
zero_columns <- apply(data, 2, function(col) any(col == 0)) 

variables_with_zero_values <- names(zero_columns[zero_columns])

cat("Columns with 0 values:", paste(variables_with_zero_values, collapse = ", "))

```
### Histograms

```{r log_trans, echo=FALSE}
data$LNMEDHVAL <- log(data$MEDHVAL)
data$LNPCTBACHMOR <- log(1 + data$PCTBACHMOR)
data$LNBELPOV100 <- log(1 + data$NBELPOV100)
data$LNPCTVACANT <- log(1 + data$PCTVACANT)
data$LNPCTSINGLES <- log(1 + data$PCTSINGLES)
```

#### Median Home Value of owner occupied housing units

The two histograms below show the distribution of our dependent variable, median home values of owner occupied housing units by census tract before and after applying a logarithmic transformation. The histogram without the logarithmic transformation peaks around 75,000 USD and is right skewed - it does not have a normal distribution. After applying a logarithmic transformation, the mean home value has a near normal distribution with a peak around 11. Our analysis will use the log-transformation of Median Household income as the independent variable because it is best practice to use a variable with a normal distribution when conducting a linear regression analysis.

```{r hist_MEDHVAL}
par(mfrow=c(1,2))
hist(data$MEDHVAL,breaks=100)
hist(data$LNMEDHVAL,breaks=100)
```
#### Percent of Population with a Bachelor Degree:

These histograms show the distribution of the percent of the population with a bachelor's degree by census tract before and after applying a logarithmic transformation. The histogram without the log transformation is right skewed, and there are 143 census blocks where 0% of the population has a bachelor degree. 

After applying a log transformation, the 143 census blocks which had a value of 0% continue to have a value of 0. The distribution with the log transformation applied is not normal and has a zero infrared distribution. Because both the variable with and without the log transformation applied are both not normal we will use the variable without the log transformation (PCTBACHMORE) for the regression.


```{r hist_PCTBACHMOR}
par(mfrow=c(1,2))
hist(data$PCTBACHMOR,breaks=100)
hist(data$LNPCTBACHMOR,breaks=100)
```
#### Population Below the Poverty Line

The histograms below show the distribution of the population living below the poverty line in each census block with and without the log transformation applied. The histogram without the log transformation, is again right skewed and peaks around 100 households. There is a very long tail to the right, and multiple outliers are present. Notably, the maximum value is 1,267 households below the poverty line in one census tract - which is more than 6 times larger than the mean value. 

After applying a log transformation, the variable displays a distribution which is closer to a normal distribution. There is a clear peak around 5.5, but the data is slightly skewed to the left and is zero inflated, but is closer to a normal distribution than the non log transformed variable. Because the log transformed variable is closer to a normal distribution we use the log transformation of the Population Below the Poverty Line (LNBELPOV100) in our regression.


```{r hist_NBELPOV100}
par(mfrow=c(1,2))
hist(data$NBELPOV100,breaks=100)
hist(data$LNBELPOV100,breaks=100)
```
#### Percent of Households units which are vacant

The histograms below show the distribution for the percent of housing units in a census tract which are vacant with and without the log transformation. The histogram without the log transformation is right skewed and has a long tail, with multiple outliers present. Additionally, there are 163 census block groups where 0% of the housing units are vacant.

After applying the log transformation, the 163 census block groups which have a value of 0% still have a value of 0, the presence of the large number of census block groups with a value of zero prevents the distribution from being considered normal and results in a zero-inflated distribution. Because neither distribution is normal we use the variable without the log transformation in our regression analysis (PCTVACANT).

```{r hist_PCTVACANT}
par(mfrow=c(1,2))
hist(data$PCTVACANT,breaks=100)
hist(data$LNPCTVACANT,breaks=100)
```
#### Percent of housing units that are detached single family houses 

The histograms below show the distribution for the percent of housing units that are detached single family homes by census block group with and without the log transformation. The histogram without the log transformation is very right skewed, and the vast majority of census block groups (i.e: 1,548) have a percentage less than 20%, and there are 306 block groups where the percentage value is 0. There are 172 census block groups which have percentages above 20% including three homes with values of 100%. The extreme outliers are likely are a result of the inclusion of sub-urban census block groups in Northeast and Northwest where most homes are detached single family homes. 

After applying the log transformation the 306 block groups where the percentage was 0, continue to have a percentage value of 0 resulting in a zero inflated distribution. Because both the log transformed and non-log transformed variable do not have a normal distribution we use the non-log transformed variable in our regression analysis.


```{r hist_PCTSINGLES}
par(mfrow=c(1,2))
hist(data$PCTSINGLES,breaks=100)
hist(data$LNPCTSINGLES,breaks=100)
```
### Maps

This section includes coloropleth maps of our dependent and four independent variables.

#### Map of Dependent Variable

This map shows our dependent variable, which is the median house value of owner occupied units by census tract with a log transformation. We observe that the census tracts with the highest median home values are primarily clustered in center city and northwest Philadelphia. The census tracts with the lowest median home values are located North of center city and in areas of West Philadelphia located west of University City. 

```{r LNMEDHVAL map}

# Change design
map <- st_read("Data/RegressionData.shp")

A <- ggplot() +
  geom_sf(data = map, aes(fill = LNMEDHVAL), color = NA) +
  scale_fill_gradient(low = "white",high = "darkseagreen4") +
  labs(title = "Log Median Home Value") +
  theme_dark() +
  theme( 
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.ticks = element_blank(),
    axis.text = element_blank()
    )

A
```

#### Maps of Independant Variables

The maps below show the spatial patterns on our four independent variables: PCTBACHMOR, PCTVACANT, PCTSINGLES, and LNBELPOV100. 
Based on a review of the maps, the PCTBACHMOR variable appears to be the independent variable with the strongest correlation with our dependent variable. Like our dependent variable, the percent of residents living in the census tract with a bachelor degree is highest in center city and in Northwest Philadelphia. The areas with the lowest percentage of residents with a bachelor degree are located in West Philadelphia west of University City and north of Center City - these are the same areas where the log transformed median home values are lowest. 

Conversely, the PCTSINGLES variable does not appear to be correlated with our dependent variable. This is because the percent of housing units that are detached single family homes tends to be low in center city, and high in Northwest Philadelphia which are both neighborhoods with high median home prices values. 

The PCTBACHMOR and PCTVACANT appear to have a strong negative correlation, as areas with a high PCTVACANT rate also have a low PCTBACHMOR rate. Conversely, areas with a high PCTBACHMOR rate have a low PCTVACANT rate. This negative correlation indicates that there may be multicollinearity between these two variables. We will check the strength of this correlation using Pearsons‚Äôs correlation to determine if this multicollinearity could be an issue in our regression.


```{r variables maps, fig.width = 12}
# Change designs
pctvacant_map <- ggplot() +
  geom_sf(data = map, aes(fill = PCTVACANT), color = NA) +
  scale_fill_gradient(low = "white",high = "darkblue") +
  labs(title = "Vacant",
       fill = "%")+
  theme_dark() +
  theme( 
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.ticks = element_blank(),
    axis.text = element_blank()
    )

pctsingles_map <- ggplot() +
  geom_sf(data = map, aes(fill = PCTSINGLES), color = NA) +
  scale_fill_gradient(low = "white",high = "darkorchid4") +
  labs(title = "Singles",
       fill = "%")+
  theme_dark() +
  theme( 
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.ticks = element_blank(),
    axis.text = element_blank()
    )

pctbachmor_map <- ggplot() +
  geom_sf(data = map, aes(fill = PCTBACHMOR), color = NA) +
  scale_fill_gradient(low = "white",high = "darkorange") +
  labs(title = "Bachelor's or More",
       fill = "%")+
  theme_dark() +
  theme( 
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.ticks = element_blank(),
    axis.text = element_blank()
    )

lnnbelpov100_map <- ggplot() +
  geom_sf(data = map, aes(fill = LNNBELPOV), color = NA) +
  scale_fill_gradient(low = "white",high = "darkred") +
  labs(title = "Log Below Poverty")+
  theme_dark() +
  theme( 
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.ticks = element_blank(),
    axis.text = element_blank()
    )

grid.arrange(pctvacant_map, pctsingles_map, pctbachmor_map, lnnbelpov100_map)

```

### Pearson correlations

correlation between our dependent variables. For example, PCTBACHMOR is negatively correlated with LNBELPOV100 and PCTVACANT is positively correlated with LNBELPOV100.

Despite the correlations, we can conclude that there is not severe multicollinearity. This is because the Pearson correlation values are all between 0.9 and -0.9. When Pearson correlation values are within this range we generally do not need to be concerned about multicollinearity. 

The Pearson correlation value for the relationship between PCTBACHMOR and PCTVACANT is -0.3 supporting our previous conclusion that there is a negative correlation between the variables. However, since the Pearson correlation is more than -0.9 we do not need to be concerned about severe multicollinearity. 


```{r pearson}
predictors <- data %>% dplyr::select(PCTBACHMOR, PCTVACANT, PCTSINGLES, LNBELPOV100)

predictors %>% 
  correlate() %>% 
  autoplot() +
  geom_text(aes(label = round(r,digits=2)),size = 8)
```

# Regression Analysis

When we review our regression analysis we start by examining the f-ratio. The f-ratio is 840.9, and the p-value associated with the f-ratio is less than 0.0001. Thus, we can reject the null hypothesis that all Œ≤ coefficients are zero. 

After reviewing the f-ratio, we proceed to reviewing the Œ≤ coefficients, standard errors, t values, and p-scores for our four dependent variables. All four dependent variables have a p-score which indicates that the Œ≤ coefficients are statistically significant and we can reject the null hypothesis that the coefficients of any of the Œ≤ coefficients are equal to 0. There is a statistically negative relationship between the Percent of Vacant homes and the log of median home value. There is also a statistically negative relationship between the log of the number of households living in poverty and the log of median home value. There is statistically positive relationship between the percent of homes which are single family homes and the log of the median home value. There is also a statistically positive relationship between the percent of individuals with a bachelors degree and the log of the median home value.

When review our Beta Coefficients it is important to remember that our dependent variable is log transform. For the percent of homes which are standalone single family homes, percent of homes which are vacant, and percent of individuals with a bachelor degree only the dependent variable is log transformed and the Beta Coefficients are less than 0.3. Thus, we can conclude that as our independent variables go up by 1 unit, the expected change in median home value is approximately $100ùõΩ_1%$. Thus, as the percent of homes which are vacant goes up by 1% the median home value will decrease by approximately 1.917%. As the percent of homes which are standalone single family homes goes up by 1% the median home value will increase by approximately 0.298%. As the percent of individuals who have a bachelors degree goes up by 1% the median home value will increase by approximately 2.091%. 

For the population below the poverty line both our independent variable and our dependent variable are both log transformed. Thus, as the population below the poverty line increases by 1% the median home value will decrease by approximately $(1.01^ùõΩ_1 ‚àí1)‚àô100%$, i.e: the median home value will decrease by approximately 0.07848%.

The R-squared value is 0.6623, indicating that 66.23% of the variance in our dependent variable is explained by our four independent variables. 33.77% of the variance is not explained by our four independent variables. Our adjusted R-squared value is 0.6615, indicating that 66.15% of the variance in our dependent variable is explained by our four independent variables after adjusting the r-squared to account for the model including more than one independent variable. 

```{r regression}
## Regression Results

fit <-lm(LNMEDHVAL ~  PCTVACANT + PCTSINGLES + PCTBACHMOR + LNBELPOV100, data=data)

summary(fit)
```

The table below shows an analysis of the variance table for our linear regression model. The Sum of Square Errors (SSE) for our model is 230.44. The Regression Sum of Squares (SSR) is equal to 451.745, and the Total Sum of Squares (SST) is equal to 672.185. We can calculate the $R^2$ for our model by dividing the SSR by the SST, i.e: 451.745 / 682.089 which equals 0.6623.


``` {r anova}
anova(fit)
```

```{r plot_stepwise}

step <- stepAIC(fit, direction="both")
# display results
step$anova

```

```{r cross-validation, message=FALSE, cache=FALSE,  echo=TRUE, results='hide', fig.show='hide'}

fit1 <- lm(LNMEDHVAL ~ PCTVACANT + PCTSINGLES + PCTBACHMOR + LNBELPOV100, data=data)
cv1 <- CVlm(data=data, fit1, m=5)

mse1 <- attr(cv1, "ms")
rmse1 <- sqrt(mse1)						  #Obtaining RMSE for model 1
rmse1

fit2 <- lm(LNMEDHVAL ~ PCTVACANT + MEDHHINC, data=data)
cv2 <- CVlm(data=data, fit2, m=5)

mse2 <- attr(cv2, "ms")
rmse2 <- sqrt(mse2)						  #Obtaining RMSE for model 2
rmse2

```

## Regression Assumptions Checks

In this section, we will discuss testing model assumptions. We have already examined the variable distributions in a prior section. 

### Scatter Plots - Looking at linearity between dependent variable (LNMEDHVAL) and predictors (LNNBELPOV100,data$PCTBACHMOR, data$PCTVACANT, data$PCTSINGLES )  
 
```{r scatter}
par(mfrow=c(2,2))
plot(data$LNBELPOV100, data$LNMEDHVAL)
plot(data$PCTBACHMOR,data$LNMEDHVAL)
plot(data$PCTVACANT, data$LNMEDHVAL)
plot(data$PCTSINGLES, data$LNMEDHVAL)
```

###Histogram of the standardized residuals
```{r resid plot}

#predicted values, residuals and standardized residuals

#Predicted values (y-hats)
data$predvals <- fitted(fit) 
#Residuals
data$resids <- residuals(fit)
#Standardized Residuals
data$stdres <- rstandard(fit)

hist(data$stdres)

```


###Standardized Residual by Predicted Value‚Äô scatter plot
```{r plot_stand_resid}

plot(data$predvals, data$stdres, xlab = "Predicted Values ", ylab = "Standardized Residuals ", main = "Predicted Values vs.Standardized Residuals ")

```


###Choropleth map of the standardized regression residuals
```{r resid map}

map2 <- cbind(map, data %>% dplyr::select(stdres))

ggplot()+
  geom_sf(data=map2, aes(fill = stdres), color = NA)+
  scale_fill_viridis_c()+
  labs(title = "Standardized Regression Residuals") +
  theme_dark() +
  theme( 
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.ticks = element_blank(),
    axis.text = element_blank()
    )

```


## Additional Models

# Discussion and Limitations